{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0  Determine number of parameters for NLP model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXkCf9hKXkIl"
      },
      "source": [
        "# Determine the number of parameters for NLP models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ZZ2c26XgJk"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1BHVSQUdSdHxr-G-rlKk3JS7FupALufyn?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIea7CKmuTYB"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaHc9qEnyUT-"
      },
      "source": [
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "def get_model_size(checkpoint='bert-base-cased'):\n",
        "  '''For use with NLP models only\n",
        "  Usage: \n",
        "      checkpoint - the NLP model\n",
        "      returns the size of the NLP model you want to determine\n",
        "  Run this on colab.research.google.com as this downloads the model \n",
        "  before calculating the number of parameters.    \n",
        "  '''\n",
        "  \n",
        "  model = TFAutoModel.from_pretrained(checkpoint)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "  model.summary()\n",
        "\n",
        "get_model_size('bert-base-cased')\n",
        "#get_model_size('bert-large-uncased')\n",
        "#get_model_size('gpt2-medium')\n",
        "#get_model_size('gpt2-xl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjHi2W4wOHAd"
      },
      "source": [
        "Go to https://huggingface.co/transformers/v3.3.1/pretrained_models.html. \n",
        "- What is a pretrained model mean?\n",
        "- What is the smallest model you can run on Colab?\n",
        "- What is the largest model you can run on Colab?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2AdQyElP2yv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}